{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ef453c2",
      "metadata": {
        "id": "3ef453c2"
      },
      "source": [
        "# preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1002b6d",
      "metadata": {
        "id": "f1002b6d"
      },
      "source": [
        "## import packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nickjourjine/peromyscus-pup-vocal-evolution.git\n",
        "%cd peromyscus-pup-vocal-evolution\n",
        "import sys\n",
        "sys.path.append(\"/content/peromyscus-pup-vocal-evolution\")\n",
        "from src import features, annotation, parameters, segmentation, spectrogramming"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGYkAPBIfNnt",
        "outputId": "d47354eb-87a9-4b1c-a176-11d78413bbb6"
      },
      "id": "TGYkAPBIfNnt",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'peromyscus-pup-vocal-evolution'...\n",
            "remote: Enumerating objects: 1051, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 1051 (delta 75), reused 83 (delta 37), pack-reused 925 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1051/1051), 37.50 MiB | 11.23 MiB/s, done.\n",
            "Resolving deltas: 100% (709/709), done.\n",
            "/content/peromyscus-pup-vocal-evolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8528ad2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-05T09:00:29.923805Z",
          "start_time": "2022-07-05T09:00:25.890311Z"
        },
        "id": "f8528ad2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "#file system\n",
        "import os\n",
        "import glob\n",
        "\n",
        "#data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#plotting\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# custom code\n",
        "from src import features, annotation, parameters, segmentation, spectrogramming\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb8d4df",
      "metadata": {
        "id": "9bb8d4df"
      },
      "source": [
        "## load path variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16623528",
      "metadata": {
        "id": "16623528"
      },
      "outputs": [],
      "source": [
        "#paths to raw unprocessed recordings for each of the four datasets (from Dryad: https://doi.org/10.5061/dryad.g79cnp5ts)\n",
        "all_wav_development = '/content/peromyscus-pup-vocal-evolution/data/audio/raw/development/'\n",
        "all_wav_bw_po_cf = '/content/peromyscus-pup-vocal-evolution/data/audio/raw/bw_po_cf/'\n",
        "all_wav_bw_po_f1 = '/content/peromyscus-pup-vocal-evolution/data/audio/raw/bw_po_f1/'\n",
        "all_wav_bw_po_f2 = '/content/peromyscus-pup-vocal-evolution/data/audio/raw/bw_po_f2/'\n",
        "\n",
        "#paths to clips for developmental dataset\n",
        "all_clips_development = '/content/peromyscus-pup-vocal-evolution/data/audio/clips/development'\n",
        "all_clips_bw_po_cf = '/content/peromyscus-pup-vocal-evolution/data/audio/clips/bw_po_cf/'\n",
        "all_clips_bw_po_f1 = '/content/peromyscus-pup-vocal-evolution/data/audio/clips/bw_po_f1/'\n",
        "all_clips_bw_po_f2 = '/content/peromyscus-pup-vocal-evolution/data/audio/clips/bw_po_f2/'\n",
        "\n",
        "#root directory for all of the segments (start and stop times)\n",
        "segments_root = '/content/peromyscus-pup-vocal-evolution/data/audio/clips/audio/segments/'\n",
        "\n",
        "#directory to save wav files of each vocalization\n",
        "clips_root = '/content/peromyscus-pup-vocal-evolution/data/audio/clips/'\n",
        "\n",
        "#directory to save spectrograms and umap embeddings\n",
        "specs_root = '/content/peromyscus-pup-vocal-evolution/data/features/spectrograms/'\n",
        "\n",
        "#directroy to save data on background noise levels for each recording\n",
        "noise_root = '/content/peromyscus-pup-vocal-evolution/data/audio/noise/'\n",
        "\n",
        "#directroy to save data on clipping levels for each vocalizations\n",
        "clipping_root = '/content/peromyscus-pup-vocal-evolution/data/features/clipping/amplitude_segmented/'\n",
        "\n",
        "# Directory to save SNR and clipping data\n",
        "snr_clipping_root = '/content/peromyscus-pup-vocal-evolution/data/features/snr_clipping/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e33ede5",
      "metadata": {
        "id": "8e33ede5"
      },
      "source": [
        "# segment the audio using amplitude thresholding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d89c900b",
      "metadata": {
        "id": "d89c900b"
      },
      "source": [
        "## set the segmenting parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "51c92190",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-20T09:31:45.448614Z",
          "start_time": "2022-06-20T09:31:45.443272Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51c92190",
        "outputId": "234048bf-287e-42aa-90f8-a320916cbc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "making a new params file...\n",
            "saved the params file to:\n",
            " peromyscus_output/segments/bw_po_cf/amplitude_segmented/20250527_113136/00_params/bw_po_cf_20250527_113136\n",
            "✅ パラメータ保存完了\n",
            "📝 保存先: peromyscus_output/segments/bw_po_cf/amplitude_segmented/20250527_113136/00_params\n",
            "📁 ファイル名: bw_po_cf_20250527_113136\n",
            "🔁 iteration: 20250527_113136\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from src import parameters  # assuming you're in the peromyscus repo\n",
        "\n",
        "# -----------------------------\n",
        "# 🔧 音声区間検出関数の定義\n",
        "# -----------------------------\n",
        "def get_onsets_offsets(spec, seg_params):\n",
        "    amp_trace = np.mean(spec, axis=0)\n",
        "    smoothing_sigma = seg_params[\"smoothing_timescale\"] * seg_params[\"fs\"]\n",
        "    amp_trace_smooth = gaussian_filter1d(amp_trace, sigma=smoothing_sigma)\n",
        "\n",
        "    mask = (amp_trace_smooth > seg_params[\"th_1\"]) | \\\n",
        "           (amp_trace_smooth > seg_params[\"th_2\"]) | \\\n",
        "           (amp_trace_smooth > seg_params[\"th_3\"])\n",
        "\n",
        "    diff = np.diff(mask.astype(int))\n",
        "    onsets = np.where(diff == 1)[0]\n",
        "    offsets = np.where(diff == -1)[0]\n",
        "\n",
        "    # 修正：対応が取れるように数合わせ\n",
        "    if offsets.size > 0 and (onsets.size == 0 or onsets[0] > offsets[0]):\n",
        "        offsets = offsets[1:]\n",
        "    if onsets.size > offsets.size:\n",
        "        onsets = onsets[:offsets.size]\n",
        "    elif offsets.size > onsets.size:\n",
        "        offsets = offsets[:onsets.size]\n",
        "\n",
        "    return onsets, offsets\n",
        "\n",
        "# -----------------------------\n",
        "# 📦 セグメントパラメータ定義\n",
        "# -----------------------------\n",
        "seg_params = {\n",
        "    'min_freq': 20e3,\n",
        "    'max_freq': 125e3,\n",
        "    'nperseg': 1024,\n",
        "    'noverlap': 1024 // 2,\n",
        "    'spec_min_val': 0.8,\n",
        "    'spec_max_val': 6,\n",
        "    'fs': 250000,\n",
        "    'th_1': 0.3,\n",
        "    'th_2': 0.3,\n",
        "    'th_3': 0.35,\n",
        "    'min_dur': 0.015,\n",
        "    'max_dur': 1,\n",
        "    'min_intersyllable': 0.004,\n",
        "    'smoothing_timescale': 0.00025,\n",
        "    'softmax': False,\n",
        "    'temperature': 0.01,\n",
        "    'thresholds_path': None,\n",
        "    'algorithm': get_onsets_offsets  # 関数をここで指定（保存時には除外）\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# 🗂️ 保存先の準備\n",
        "# -----------------------------\n",
        "dataset = 'bw_po_cf'\n",
        "segments_root = 'peromyscus_output/segments'  # 必要なら修正\n",
        "iteration = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "params_save_name = f\"{dataset}_{iteration}\"\n",
        "params_save_dir = os.path.join(segments_root, dataset, 'amplitude_segmented', iteration, '00_params')\n",
        "\n",
        "# ディレクトリ作成\n",
        "os.makedirs(params_save_dir, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 💾 パラメータ保存（algorithmを除く）\n",
        "# -----------------------------\n",
        "import copy\n",
        "seg_params_for_save = copy.deepcopy(seg_params)\n",
        "seg_params_for_save.pop(\"algorithm\")  # 関数は保存できない\n",
        "\n",
        "# 保存実行\n",
        "parameters.save(params=seg_params_for_save, save_dir=params_save_dir, save_name=params_save_name)\n",
        "\n",
        "# 確認出力\n",
        "print(\"✅ パラメータ保存完了\")\n",
        "print(\"📝 保存先:\", params_save_dir)\n",
        "print(\"📁 ファイル名:\", params_save_name)\n",
        "print(\"🔁 iteration:\", iteration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b9d91bc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9d91bc7",
        "outputId": "40d8edca-f130-4dd8-950f-e96bad730a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "making a new params file...\n",
            "saved the params file to:\n",
            " peromyscus_output/segments/bw_po_cf/amplitude_segmented/20250527_113136/00_params/MZ_bw_po_cf_20250527_113136\n"
          ]
        }
      ],
      "source": [
        "#choose the parameters for  MZ\n",
        "seg_params = {\n",
        "    'min_freq': 20e3, # minimum frequency\n",
        "    'max_freq': 125e3, # maximum frequency\n",
        "    'nperseg': 1024, # FFT\n",
        "    'noverlap': 1024//2, # FFT\n",
        "    'spec_min_val': 2, # minimum log-spectrogram value\n",
        "    'spec_max_val': 6, # maximum log-spectrogram value\n",
        "    'fs': 250000, # audio samplerate\n",
        "    'th_1':.3, # segmenting threshold 1\n",
        "    'th_2':.3, # segmenting threshold 2\n",
        "    'th_3':.35, # segmenting threshold 3\n",
        "    'min_dur':0.015, # minimum syllable duration\n",
        "    'max_dur': 1, # maximum syllable duration\n",
        "    'min_intersyllable': .004,\n",
        "    'smoothing_timescale': 0.00025, # amplitude\n",
        "    'softmax': False, # apply softmax to the frequency bins to calculate\n",
        "                      # amplitude\n",
        "    'temperature':0.01, # softmax temperature parameter\n",
        "    'thresholds_path': None,\n",
        "    'algorithm': '<function get_onsets_offsets at 0x7f944cc355f0>', # (defined above)\n",
        "}\n",
        "\n",
        "\n",
        "#name them\n",
        "params_save_name = ('_').join(['MZ',dataset,iteration])\n",
        "params_save_dir = os.path.join(segments_root,dataset,'amplitude_segmented',iteration,'00_params')+'/'\n",
        "\n",
        "#save them\n",
        "assert os.path.exists(params_save_dir)\n",
        "assert params_save_dir.endswith('/')\n",
        "parameters.save(params = seg_params, save_dir = params_save_dir, save_name = params_save_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d31b0b7",
      "metadata": {
        "id": "5d31b0b7"
      },
      "source": [
        "## segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "71a2cf26",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-20T09:31:54.501740Z",
          "start_time": "2022-06-20T09:31:54.437225Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "71a2cf26",
        "outputId": "1e8cf61b-4476-4fb3-e576-0505ffe0a724"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/peromyscus-pup-vocal-evolution/data/audio/raw/bw_po_cf/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3d47e4c3f32f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munsegmentable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#specify the directory where segment csvs will be saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/peromyscus-pup-vocal-evolution/data/audio/raw/bw_po_cf/'"
          ]
        }
      ],
      "source": [
        "#get raw audio to segment\n",
        "\n",
        "# change these if you want to keep segmenting from a previous iterationn\n",
        "\n",
        "if dataset == 'development':\n",
        "    raw_dir = all_wav_raw\n",
        "elif dataset == 'bw_po_cf':\n",
        "    raw_dir = all_wav_bw_po_cf\n",
        "elif dataset == 'bw_po_f1':\n",
        "    raw_dir = all_wav_bw_po_f1\n",
        "elif dataset == 'bw_po_f2':\n",
        "    raw_dir = all_wav_bw_po_f2\n",
        "\n",
        "if dataset == 'bw_po_cf':\n",
        "    species_list = ['BW', 'PO', 'CF-BW', 'CF-PO']\n",
        "elif dataset == 'development':\n",
        "    species_list = ['NB', 'PO', 'MZ', 'BK', 'LL', 'MU', 'BW', 'GO', 'SW', 'LO', 'IS']\n",
        "\n",
        "#if the dataset is bw_po_f2, ensure that the corrupted unsegmented files aren't in raw_dir\n",
        "unsegmentable = ['ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup4_ch8_4700_f_333_298_fr0_p9_2021-04-16_15-26-07.wav',\n",
        "                 'ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup7_ch8_3800_f_338_285_fr0_p7_2021-04-14_17-27-18.wav',\n",
        "                 'ch8_BWxPO-cross-F2_27404x27407_fam-A7_ltr1_pup7_ch8_4200_m_328_275_fr1_p7_2021-01-05_13-47-10.wav']\n",
        "\n",
        "for i in unsegmentable:\n",
        "    assert i not in os.listdir(raw_dir)\n",
        "\n",
        "#specify the directory where segment csvs will be saved\n",
        "save_dir = os.path.join(segments_root,dataset,'amplitude_segmented',iteration)\n",
        "\n",
        "#load the params and make sure everything looks ok\n",
        "print('\\ndata set is:\\n\\t',dataset, '\\n')\n",
        "\n",
        "# load the parameters\n",
        "params_save_dir = os.path.join(segments_root,dataset,'amplitude_segmented',iteration,'00_params')+'/'\n",
        "params_save_name = ('_').join([dataset,iteration])\n",
        "seg_params = parameters.load(save_dir = params_save_dir, save_name = params_save_name)\n",
        "\n",
        "if dataset == 'development':\n",
        "    MZ_seg_params = parameters.load(save_dir = params_save_dir, save_name = ('_').join(['MZ',dataset,iteration]))\n",
        "\n",
        "print('\\nthey are:\\n')\n",
        "for key in seg_params.keys():\n",
        "    print('\\t',key,':',seg_params[key])\n",
        "\n",
        "if dataset == 'development':\n",
        "    print('\\nMZ specific params are:\\n')\n",
        "    for key in seg_params.keys():\n",
        "        print('\\t',key,':',MZ_seg_params[key])\n",
        "\n",
        "print('\\nstart and stop times will be identified in raw wav files here:\\n\\t', raw_dir)\n",
        "print('\\nand saved here:\\n\\t', save_dir)\n",
        "\n",
        "val = input('everything look ok for segmenting? y/n')\n",
        "assert val in ['y','n']\n",
        "if val == 'n':\n",
        "    print('ok - doing nothing')\n",
        "elif val == 'y':\n",
        "\n",
        "    #iterate through each species you want and segment\n",
        "    for species in species_list:\n",
        "\n",
        "        #get the MZ specific parameters if you're segmenting MZ\n",
        "        if species=='MZ':\n",
        "            seg_params = parameters.load(save_dir = params_save_dir, save_name = ('_').join(['MZ',dataset,iteration]))\n",
        "\n",
        "        segmentation.get_amplitude_segments(audio_dir = raw_dir,\n",
        "                                            save_dir = save_dir,\n",
        "                                            seg_params = seg_params,\n",
        "                                            species = species,\n",
        "                                            thresholds_path = seg_params['thresholds_path'],\n",
        "                                            intersyll_threshold = seg_params['min_intersyllable'],\n",
        "                                            duration_threshold = seg_params['min_dur'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76827c58",
      "metadata": {
        "id": "76827c58"
      },
      "source": [
        "## aggregate the segments files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf483ad",
      "metadata": {
        "id": "5bf483ad"
      },
      "outputs": [],
      "source": [
        "#choose the dataset and segmenting iteration if you want (otherwise will existing values for dataset and iteration\n",
        "#- these are the only things you have to change in this cell to process a new dataset\n",
        "dataset = 'bw_po_f2'\n",
        "iteration = '20220921_040238'\n",
        "\n",
        "#path to the dir containing one csv with segment start and stop times per raw audio file\n",
        "segments_path = os.path.join(segments_root,dataset,'amplitude_segmented',iteration)\n",
        "\n",
        "\n",
        "#make sure you segmented every wav file\n",
        "if dataset == 'development':\n",
        "    all_wav_raw = all_wav_raw\n",
        "elif dataset == 'bw_po_cf':\n",
        "    all_wav_raw = all_wav_bw_po_cf\n",
        "elif dataset == 'bw_po_f1':\n",
        "    all_wav_raw = all_wav_bw_po_f1\n",
        "elif dataset == 'bw_po_f2':\n",
        "    all_wav_raw = all_wav_bw_po_f2\n",
        "\n",
        "\n",
        "raw_wavs = [i for i in os.listdir(all_wav_raw) if not i.startswith('.')]\n",
        "segmented_wavs = [i.split('.')[0]+'.wav' for i in os.listdir(segments_path) if not i.startswith('.') and 'all' not in i]\n",
        "assert sorted(raw_wavs) == sorted(segmented_wavs), \"You haven't segmented all of the raw wav files...\"\n",
        "\n",
        "#make a list of the segments files for each pup\n",
        "pup_segments = [os.path.join(segments_path, i) for i in os.listdir(segments_path) if i.endswith('.csv') and 'all' not in i and not i.startswith('.')]\n",
        "\n",
        "#combine them\n",
        "to_combine = []\n",
        "for temp in pup_segments:\n",
        "    temp_df = pd.read_csv(temp)\n",
        "    to_combine.append(temp_df)\n",
        "\n",
        "all_combined = pd.concat(to_combine)\n",
        "\n",
        "#add species column info and fix up the source_file columns\n",
        "all_combined['species'] = [i.split('/')[-1].split('_')[0] for i in all_combined['source_file']]\n",
        "all_combined['source_file'] = [os.path.split(i)[-1] for i in all_combined['source_file']]\n",
        "\n",
        "#check for na and duplications, make sure source file is formatted correctly, then save\n",
        "\n",
        "assert all_combined.isna().sum().sum() == 0\n",
        "assert all_combined.duplicated().sum() == 0\n",
        "assert set([i.split('_')[0] for i in all_combined['source_file']]) == set(all_combined['species'])\n",
        "all_combined.to_csv(os.path.join(segments_path, 'all_combined.csv'), index=False)\n",
        "print('saved a combined file to:\\n\\t', os.path.join(segments_path, 'all_combined.csv'))\n",
        "\n",
        "#preview to make sure column names look ok\n",
        "all_combined.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45fafb07",
      "metadata": {
        "id": "45fafb07"
      },
      "source": [
        "# generate wav clips from amplitude segmented segments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eded6b7",
      "metadata": {
        "id": "0eded6b7"
      },
      "source": [
        "## write wav files for vocalizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e047c1",
      "metadata": {
        "id": "70e047c1"
      },
      "outputs": [],
      "source": [
        "#choose the dataset and iteration\n",
        "\n",
        "#load the combined segments csv\n",
        "segments_path = os.path.join(segments_root,dataset,'amplitude_segmented',iteration)\n",
        "source_data_path = os.path.join(segments_path, 'all_combined.csv')\n",
        "source_data = pd.read_csv(source_data_path)\n",
        "\n",
        "#make it's what you expect and that you cleaned up any na and duplications\n",
        "assert source_data.isna().sum().sum() == 0\n",
        "assert source_data.duplicated().sum() == 0\n",
        "assert set(source_data.columns) == set(['start_seconds', 'stop_seconds', 'source_file', 'duration', 'species'])\n",
        "\n",
        "if dataset == 'bw_po_cf':\n",
        "    assert set(source_data['species'].unique()) == set(['BW', 'PO', 'CF-BW', 'CF-PO'])\n",
        "elif dataset == 'bw_po_f1':\n",
        "    assert set(source_data['species'].unique()) == set(['cross-BW', 'cross-PO', 'BW-PO-cross-F1'])\n",
        "elif dataset == 'bw_po_f2':\n",
        "    assert set(source_data['species'].unique()) == set(['ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7', 'ch8'])\n",
        "    #drop the unsegmentable bw_po_f2\n",
        "    unsegmentable = ['ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup4_ch8_4700_f_333_298_fr0_p9_2021-04-16_15-26-07.wav',\n",
        "                 'ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup7_ch8_3800_f_338_285_fr0_p7_2021-04-14_17-27-18.wav',\n",
        "                 'ch8_BWxPO-cross-F2_27404x27407_fam-A7_ltr1_pup7_ch8_4200_m_328_275_fr1_p7_2021-01-05_13-47-10.wav']\n",
        "    source_data = source_data.loc[~source_data['source_file'].isin(unsegmentable)]\n",
        "\n",
        "elif dataset == 'development':\n",
        "    assert sorted(species_list) == sorted(['BW', 'BK', 'NB', 'SW', 'PO', 'LO', 'GO', 'LL', 'MU', 'MZ'])\n",
        "\n",
        "#get the path to the raw unsegmented wavs\n",
        "if dataset == 'bw_po_cf':\n",
        "    wavs_dir = all_wav_bw_po_cf\n",
        "elif dataset == 'bw_po_f1':\n",
        "    wavs_dir = all_wav_bw_po_f1\n",
        "elif dataset == 'bw_po_f2':\n",
        "    wavs_dir = all_wav_bw_po_f2\n",
        "elif dataset == 'development':\n",
        "    wavs_dir = all_wav_raw\n",
        "\n",
        "bar = '######################################################################################################'\n",
        "#set the directory for saving and make it TODO - get the data from datetime\n",
        "save_root = os.path.join(clips_root,'amplitude_segmented',dataset, iteration)\n",
        "if iteration not in os.listdir(os.path.join(clips_root,'amplitude_segmented',dataset)):\n",
        "    os.mkdir(save_root)\n",
        "    print('made a directory to save vocalization clips:', save_root)\n",
        "assert os.path.exists(save_root)\n",
        "\n",
        "print(bar)\n",
        "print('segmenting wavs from this directory:\\n\\n',wavs_dir,'\\n')\n",
        "print(bar)\n",
        "print('using start and stop times from this file:\\n\\n',source_data_path,'\\n')\n",
        "print(bar)\n",
        "print('saving them to individual species directories here:\\n\\n',save_root,'\\n')\n",
        "print(bar)\n",
        "print('those species are:\\n\\n',sorted(source_data['species'].unique()),'\\n')\n",
        "print(bar)\n",
        "print(len(source_data), 'vocalization clips will be written to wav files')\n",
        "\n",
        "val = input(\"continue? y/n\")\n",
        "assert val in ['y', 'n']\n",
        "if val == 'n':\n",
        "    print('ok - doing nothing.')\n",
        "elif val == 'y':\n",
        "#iterate through the species\n",
        "    species_list = list(source_data['species'].unique())\n",
        "    for species in species_list:\n",
        "        print(species)\n",
        "\n",
        "        save_location = os.path.join(save_root,species)\n",
        "        start_column = 'start_seconds'\n",
        "        end_column = 'stop_seconds'\n",
        "\n",
        "        if species not in os.listdir(save_root):\n",
        "            print('making a directory to store', species, 'vocalization clips...')\n",
        "            os.mkdir(save_location)\n",
        "\n",
        "        segmentation.get_wav_clips(wavs_dir = wavs_dir,\n",
        "                                   save_location = save_location,\n",
        "                                   source_data = source_data,\n",
        "                                   start_column = start_column,\n",
        "                                   end_column = end_column,\n",
        "                                   label_column = None,\n",
        "                                   species = species,\n",
        "                                   margin = 0,\n",
        "                                   units = 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe472c9",
      "metadata": {
        "id": "7fe472c9"
      },
      "source": [
        "## write wav files for inter-vocalization intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44bfe21c",
      "metadata": {
        "id": "44bfe21c"
      },
      "outputs": [],
      "source": [
        "#segment background using - useful for finding wav clips that don't have any vocalizations in them\n",
        "# dataset = 'bw_po_f2'\n",
        "# iteration = '20220921_040238'\n",
        "\n",
        "#choose the species and directories where things will be saved\n",
        "species =['MZ']\n",
        "\n",
        "#name the columns that will record start and stop time of background in seconds\n",
        "start_column = 'start_seconds'\n",
        "stop_column = 'stop_seconds'\n",
        "\n",
        "#set directories automatically\n",
        "raw_wavs_dir = os.path.join(all_wavs_raw, dataset, iteration)\n",
        "save_dir = os.path.join(save_dir, '01_background_clips')\n",
        "if not os.path.exists(save_dir):\n",
        "    os.path.mkdir(save_dir)\n",
        "    print('made a directory at', save_dir)\n",
        "\n",
        "#path to the csv made in the previous cell\n",
        "all_segments_df = os.path.join(segments_path, 'all_combined.csv')\n",
        "\n",
        "\n",
        "for s in species:\n",
        "    save_location = save_dir+s+'/'\n",
        "\n",
        "    #make a directory for the species\n",
        "    if s not in os.listdir(save_dir):\n",
        "        print('making a directory to store', s, 'background clips...')\n",
        "        save_location = save_dir+s+'/'\n",
        "        os.mkdir(save_location)\n",
        "\n",
        "    segmentation.get_background_clips(raw_wavs_dir=raw_wavs_dir ,\n",
        "                                      save_location=save_location,\n",
        "                                      all_segments_df=all_segments_df,\n",
        "                                      start_column=start_column,\n",
        "                                      stop_column=stop_column,\n",
        "                                      label_column = None,\n",
        "                                      species = s,\n",
        "                                      units = 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4cc4670",
      "metadata": {
        "id": "d4cc4670"
      },
      "source": [
        "## choose noise clips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2b4be7",
      "metadata": {
        "id": "7a2b4be7"
      },
      "outputs": [],
      "source": [
        "#best to run this cell one species at a time and save clips to species specific directories\n",
        "species = 'BK'\n",
        "\n",
        "#path to directory containing raw audio\n",
        "audio_dir = all_wav_raw\n",
        "\n",
        "#path to directory containing segments generated in section 2.2 above\n",
        "dataset = 'development'\n",
        "iteration='20230118_083823'\n",
        "seg_df = os.path.join(segments_root,dataset,'amplitude_segmented',iteration, 'all_combined.csv')\n",
        "\n",
        "#path to save wav clips\n",
        "save_dir = os.path.join(noise_root, 'test_20230120', species)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.mkdir(save_dir)\n",
        "    print('made the directory', save_dir)\n",
        "\n",
        "pups = sorted([i.split('.')[0] for i in os.listdir(all_wav_raw) if species in i])\n",
        "\n",
        "for pup in pups:\n",
        "    annotation.get_noise_clip(pup=pup,\n",
        "                              audio_dir=audio_dir,\n",
        "                              seg_csv=seg_df,\n",
        "                              save_dir=save_dir,\n",
        "                              margin=0,\n",
        "                              min_dur=2,\n",
        "                              max_dur=3,\n",
        "                              units = 's')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03aacac",
      "metadata": {
        "id": "e03aacac"
      },
      "source": [
        "## calculate noise floors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a80e96",
      "metadata": {
        "id": "24a80e96",
        "outputId": "8e3fcf5e-b090-47b5-84a5-8d00daacbca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done.\n"
          ]
        }
      ],
      "source": [
        "#use the background clips in cell 3.3 above to calculate \"noise floors\", ie the spectrogram value\n",
        "#below which you will consider a pixel \"background\"\n",
        "\n",
        "save_dir = os.path.join(noise_root, 'test_20230120')\n",
        "species_list = ['BW', 'BK', 'NB', 'SW', 'PO', 'LO', 'GO', 'LL', 'MU', 'MZ', 'IS']\n",
        "\n",
        "\n",
        "noise_spec_params = {\n",
        "    'min_freq': 5000, # minimum frequency\n",
        "    'max_freq': 125000, # maximum frequency\n",
        "    'nperseg': 512, # FFT\n",
        "    'noverlap': 512 // 4, # FFT\n",
        "    'fs': 250000, # audio samplerate\n",
        "\n",
        "}\n",
        "\n",
        "parameters.save_parameters(params = noise_spec_params,\n",
        "                           save_dir = save_root,\n",
        "                           save_name = 'noise_spec_params')\n",
        "\n",
        "noise_floors_df = []\n",
        "for species in species_list:\n",
        "    df =  annotation.get_noise_floor(noise_dir = os.path.join(noise_root, species),\n",
        "                                     thresh = 2,\n",
        "                                     species = species,\n",
        "                                     save_dir = save_dir,\n",
        "                                     spec_params = noise_spec_params,\n",
        "                                     verbose=False,\n",
        "                                     save = False)\n",
        "\n",
        "    noise_floors_df.append(df)\n",
        "\n",
        "new = pd.concat(noise_floors_df)\n",
        "print('done.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62513de8",
      "metadata": {
        "id": "62513de8"
      },
      "source": [
        "# get clipping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe3dd3c3",
      "metadata": {
        "id": "fe3dd3c3"
      },
      "source": [
        "## set spectrogramming parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7d89e7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-15T13:10:41.043897Z",
          "start_time": "2022-06-15T13:10:41.038199Z"
        },
        "id": "3a7d89e7"
      },
      "outputs": [],
      "source": [
        "#choose params that match the ones you will use for getting features\n",
        "noise_spec_params = {\n",
        "    'min_freq': 5000, # minimum frequency\n",
        "    'max_freq': 12500, # maximum frequency\n",
        "    'nperseg': 1024, # FFT\n",
        "    'noverlap': 1024 // 4, # FFT\n",
        "    'fs': 250000, # audio samplerate\n",
        "}\n",
        "\n",
        "spec_params = {\n",
        "    'min_freq': 5000, # minimum frequency\n",
        "    'max_freq': 124999, # maximum frequency\n",
        "    'nperseg': 256, # FFT\n",
        "    'noverlap': 256 // 4, # FFT\n",
        "    'spec_min_val': 0.7, # minimum log-spectrogram value\n",
        "    'fs': 250000, # audio samplerate\n",
        "    'downsample_by':2, #2 means take every other pixel from the original spectrogram\n",
        "    'log_resize_scaling_factor':None\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a107d191",
      "metadata": {
        "id": "a107d191"
      },
      "source": [
        "## get noise floors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d703ab4c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-15T11:46:13.552205Z",
          "start_time": "2022-06-15T11:46:12.965033Z"
        },
        "id": "d703ab4c"
      },
      "outputs": [],
      "source": [
        "noise_floors_path = '/peromyscus-pup-vocal-evolution/data/audio/noise/all_noise_floors.csv'\n",
        "nfdf = pd.read_csv(noise_floors_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b9c1b9",
      "metadata": {
        "id": "05b9c1b9"
      },
      "source": [
        "## get clipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552740a5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-07-05T09:01:40.807108Z",
          "start_time": "2022-07-05T09:01:40.804370Z"
        },
        "id": "552740a5"
      },
      "outputs": [],
      "source": [
        "clipping_threshold = 0.95\n",
        "dataset = 'bw_po_cf'\n",
        "iteration = '20230206_050454'\n",
        "#iteration = '20230206_99thresh'\n",
        "save = True\n",
        "\n",
        "if save:\n",
        "    if not os.path.exists(os.path.join(snr_clipping_root,dataset,iteration)):\n",
        "        os.mkdir(os.path.join(snr_clipping_root,dataset,iteration))\n",
        "\n",
        "################################################################################################################\n",
        "\n",
        "if dataset == 'bw_po_cf':\n",
        "    to_process_dir = os.path.join(all_clips_bw_po_cf, iteration)\n",
        "    species_list = os.listdir(to_process_dir)\n",
        "    assert set(species_list) == set(['BW', 'PO', 'CF-BW', 'CF-PO'])\n",
        "\n",
        "elif dataset == 'bw_po_f1':\n",
        "    to_process_dir = all_clips_bw_po_f1\n",
        "    species_list = os.listdir(to_process_dir)\n",
        "    assert set(species_list) == set(['cross-BW', 'cross-PO', 'BW-PO-cross-F1'])\n",
        "\n",
        "elif dataset == 'bw_po_f2':\n",
        "    to_process_dir = all_clips_bw_po_f2\n",
        "    species_list = os.listdir(to_process_dir)\n",
        "    assert set(species_list) == set(['ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7', 'ch8'])\n",
        "\n",
        "    #drop the unsegmentable bw_po_f2\n",
        "    unsegmentable = ['ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup4_ch8_4700_f_333_298_fr0_p9_2021-04-16_15-26-07.wav',\n",
        "                 'ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup7_ch8_3800_f_338_285_fr0_p7_2021-04-14_17-27-18.wav',\n",
        "                 'ch8_BWxPO-cross-F2_27404x27407_fam-A7_ltr1_pup7_ch8_4200_m_328_275_fr1_p7_2021-01-05_13-47-10.wav']\n",
        "    source_data = source_data.loc[~source_data['source_file'].isin(unsegmentable)]\n",
        "\n",
        "elif dataset == 'development':\n",
        "    print('dataset is:', dataset)\n",
        "    to_process_dir = all_clips_development\n",
        "    species_list = os.listdir(to_process_dir)\n",
        "    assert sorted(species_list) == sorted(['BW', 'BK', 'NB', 'SW', 'PO', 'LO', 'GO', 'LL', 'MU', 'MZ', 'IS'])\n",
        "\n",
        "#get clipping percents and corresponding to each wav file\n",
        "\n",
        "clipping_dfs = []\n",
        "for species in species_list:\n",
        "    print('calculating clipping for each vocalization clip in:\\n\\t', os.path.join(to_process_dir, species))\n",
        "    clipping_df = features.get_clipping_batch(wav_dir = os.path.join(to_process_dir, species),\n",
        "                                              threshold = clipping_threshold,\n",
        "                                              species = species)\n",
        "    if save:\n",
        "        save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
        "        save_name = ('_').join([species,'clipping.csv'])\n",
        "\n",
        "        if save_name not in os.listdir(save_dir):\n",
        "            clipping_df.to_csv(os.path.join(save_dir,save_name), index=False)\n",
        "            print('\\tsaved clipping csv to:', os.path.join(save_dir,save_name))\n",
        "        else:\n",
        "            print('\\tclipping csv already exists...')\n",
        "\n",
        "print('done.')\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07288280",
      "metadata": {
        "id": "07288280"
      },
      "outputs": [],
      "source": [
        "## aggregate clipping cvs\n",
        "\n",
        "save = True\n",
        "\n",
        "dataset = 'bw_po_cf'\n",
        "iteration = iteration\n",
        "\n",
        "save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
        "save_name = ('_').join(['all', dataset, 'clipping.csv'])\n",
        "to_aggregate = [i for i in glob.glob(os.path.join(save_dir, '*clipping.csv')) if os.path.split(i)[-1] != save_name]\n",
        "\n",
        "all_clipping = []\n",
        "for file in to_aggregate:\n",
        "    df = pd.read_csv(file)\n",
        "    all_clipping.append(df)\n",
        "\n",
        "all_clipping_df = pd.concat(all_clipping)\n",
        "\n",
        "if save:\n",
        "    save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
        "    if not os.path.exists(os.path.join(save_dir,save_name)):\n",
        "        all_clipping_df.to_csv(os.path.join(save_dir,save_name), index=False)\n",
        "        print('saved a file:', os.path.join(save_dir,save_name))\n",
        "\n",
        "print('done.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f72cfa",
      "metadata": {
        "id": "65f72cfa"
      },
      "source": [
        "# UMAP embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76a9c2e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-01-06T08:59:02.958891Z",
          "start_time": "2023-01-06T08:59:02.956283Z"
        },
        "id": "b76a9c2e"
      },
      "source": [
        "## set species and paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1edae9b9",
      "metadata": {
        "id": "1edae9b9"
      },
      "outputs": [],
      "source": [
        "#set the species to process\n",
        "species_list = ['PO','BW', 'BK', 'NB', 'SW', 'LO', 'GO', 'LL', 'MU', 'MZ']\n",
        "\n",
        "#the dataset for umap\n",
        "dataset = 'development'\n",
        "segment_iteration = '20230118_083823' #this is the segmenting iteration for the segments in the preprint\n",
        "\n",
        "#unique iteration ID for each time you do an embedding for a dataset\n",
        "umap_iteration = parameters.get_date_time()\n",
        "\n",
        "#all predicted start and stop times for this dataset\n",
        "aggregated_segments_path = os.path.join(segments_root,dataset,'amplitude_segmented',segment_iteration,'all_combined.csv')\n",
        "seg_df = pd.read_csv(aggregated_segments_path)\n",
        "\n",
        "#path to wav files for each segmented vocalization\n",
        "all_wav_dir = os.path.join(clips_root,'amplitude_segmented',dataset,segment_iteration)\n",
        "assert os.path.exists(all_wav_dir)\n",
        "\n",
        "#path to directory where spectrograms and umap embedding coordinates will be save\n",
        "all_spec_dir = os.path.join(specs_root,'amplitude_segmented',dataset, segment_iteration)\n",
        "if segment_iteration not in os.listdir(os.path.join(specs_root,'amplitude_segmented',dataset)):\n",
        "    os.mkdir(all_spec_dir)\n",
        "    print('made a directory to store spectrograms for umap embeddings :\\t\\n', all_spec_dir, '\\n')\n",
        "assert os.path.exists(all_spec_dir)\n",
        "\n",
        "#path to the noise floors csvs generated by annotation.get_noise_clip() and annotation.get_noise_floor()\n",
        "assert os.path.exists(noise_floors_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecdcbaae",
      "metadata": {
        "id": "ecdcbaae"
      },
      "source": [
        "## choose and save spectrogram parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bca9315",
      "metadata": {
        "id": "5bca9315"
      },
      "outputs": [],
      "source": [
        "#write the spec params\n",
        "\n",
        "umap_iteration = '20230120_105045'\n",
        "\n",
        "#make necessary directories for spectrograms\n",
        "specs_dir = os.path.join(all_spec_dir,umap_iteration)+'/'\n",
        "if umap_iteration not in os.listdir(all_spec_dir):\n",
        "    os.mkdir(specs_dir)\n",
        "    print('made a root directory to store umap embeddings from this version_name:\\t\\n', specs_dir, '\\n')\n",
        "\n",
        "if '00_params' not in os.listdir(specs_dir):\n",
        "    os.mkdir(os.path.join(specs_dir,'00_params'))\n",
        "    print('made a params directory to store umap embeddings from this version_name:\\t\\n', specs_dir+'00_params\\n')\n",
        "\n",
        "#write the params dictionaries for each species\n",
        "for species in species_list:\n",
        "    species_param_name = ('_').join([species,'spec_params',umap_iteration])\n",
        "    species_wav_clips_dir = os.path.join(clips_root, 'amplitude_segmented', dataset, segment_iteration, 'vocalization_clips', species)\n",
        "    max_dur = float(np.max(seg_df['duration'].loc[seg_df['species'] == species]))\n",
        "    print('longest predicted voc from', species, 'is', max_dur, 'seconds')\n",
        "\n",
        "    spec_params = {\n",
        "        'species': species,\n",
        "        'min_freq': 5000, # minimum frequency\n",
        "        'max_freq': 125000, # maximum frequency\n",
        "        'nperseg': 512, # FFT\n",
        "        'noverlap': 512 // 4, # FFT\n",
        "        'spec_min_val': .5, # minimum log-spectrogram value - update from noise floors dataframe if noise_floors_path provided\n",
        "        'fs': 250000, # audio samplerate\n",
        "        'fill_value': .5,\n",
        "        'max_duration':max_dur,\n",
        "        'num_time_bins':128,\n",
        "        'num_freq_bins':128,\n",
        "        'spec_max_val':10,\n",
        "        'wav_clips_source':species_wav_clips_dir,\n",
        "        'noise_floors_path': noise_floors_path\n",
        "    }\n",
        "\n",
        "    #save spec params if they don't exist\n",
        "    parameters.save_parameters(spec_params, os.path.join(specs_dir,'00_params'), species_param_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdfadac1",
      "metadata": {
        "id": "fdfadac1"
      },
      "source": [
        "## find UMAP embeddings for each species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab4c85ea",
      "metadata": {
        "id": "ab4c85ea"
      },
      "outputs": [],
      "source": [
        "#set the directory for saving and make it TODO - get the data from datetime\n",
        "dataset = 'development'\n",
        "species_list = ['PO','BW', 'BK', 'NB', 'SW', 'LO', 'GO', 'LL', 'MU', 'MZ']\n",
        "segment_iteration = '20230118_083823'\n",
        "umap_iteration = '20230120_105045'\n",
        "\n",
        "for species in species_list:\n",
        "    print('##########################################################################')\n",
        "    species_wav_clips_dir = os.path.join(clips_root, 'amplitude_segmented', dataset, segment_iteration, 'vocalization_clips', species)\n",
        "    species_param_name = ('_').join([species,'spec_params',umap_iteration])\n",
        "    print(species)\n",
        "    print('##########################################################################')\n",
        "    print('getting umap embedding from wav clips here.......\\n\\n',species_wav_clips_dir ,'\\n')\n",
        "    print('using these parameters..............\\n\\n', os.path.join(specs_dir+'00_params/', species_param_name), '\\n')\n",
        "    print('and saving umap coordinates here.......\\n\\n',specs_dir,'\\n')\n",
        "    print(len(seg_df.loc[seg_df['species'] == species]), 'vocalization clips will be processed')\n",
        "\n",
        "val = input('continue?' 'y/n')\n",
        "\n",
        "assert val in ['y', 'n']\n",
        "\n",
        "if val == 'n':\n",
        "    print('ok - doing nothing.')\n",
        "\n",
        "elif val == 'y':\n",
        "\n",
        "    for species in species_list:\n",
        "        params_dir = os.path.join(specs_dir+'00_params/')\n",
        "        params_name = ('_').join([species,'spec_params',umap_iteration])\n",
        "\n",
        "        #load the spec params\n",
        "        print('loading parameters...')\n",
        "        spec_params = parameters.load_parameters(params_dir, params_name)\n",
        "        print('done.')\n",
        "\n",
        "        #get the clips for the embedding (excluding noise)\n",
        "        print('getting paths to wav clips...')\n",
        "        clips_to_process = [i for i in glob.glob(os.path.join(spec_params['wav_clips_source'],'*.wav'))]\n",
        "        print('done.')\n",
        "\n",
        "        #make the umap\n",
        "        print('getting umap embeddings...')\n",
        "        spectrogramming.wavs_to_umap(clips_dir=None,\n",
        "                                     noise_floors_path = spec_params['noise_floors_path'],\n",
        "                                     species = None,\n",
        "                                     noise_floor = None,\n",
        "                                     spec_params = spec_params,\n",
        "                                     num_to_process = 'all',\n",
        "                                     filtered_clips = clips_to_process,\n",
        "                                     version=umap_iteration,\n",
        "                                     save_root = specs_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "manuscript",
      "language": "python",
      "name": "manuscript"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "275.99px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}