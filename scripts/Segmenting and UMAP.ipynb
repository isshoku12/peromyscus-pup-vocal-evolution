{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef453c2",
   "metadata": {},
   "source": [
    "# preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1002b6d",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8528ad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T09:00:29.923805Z",
     "start_time": "2022-07-05T09:00:25.890311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#file system\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#plotting\n",
    "import seaborn as sns \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom code\n",
    "from src import features, annotation, parameters, segmentation, spectrogramming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8d4df",
   "metadata": {},
   "source": [
    "## load path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16623528",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: put these is a paths.py file and run it here using %run /path/to/file.py\n",
    "\n",
    "#paths to raw data\n",
    "all_wav_development = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/raw/development/'\n",
    "all_wav_bw_po_cf = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/raw/bw_po_cf/'\n",
    "all_wav_bw_po_f1 = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/raw/bw_po_f1/'\n",
    "all_wav_bw_po_f2 = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/raw/bw_po_f2/'\n",
    "\n",
    "#paths to clips for developmental dataset\n",
    "all_clips_development = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/clips/amplitude_segmented/development/final_20220817/vocalization_clips/'\n",
    "all_bg_clips_development = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/clips/amplitude_segmented/development/final_20220817/background_clips/'\n",
    "all_clips_bw_po_cf = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/clips/amplitude_segmented/bw_po_cf/'\n",
    "all_clips_bw_po_f1 = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/clips/amplitude_segmented/bw_po_f1/'\n",
    "all_clips_bw_po_f2 = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/clips/amplitude_segmented/bw_po_f2/'\n",
    "\n",
    "\n",
    "#root directory for all of the segments (start and stop times)\n",
    "segments_root = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/segments/'\n",
    "clips_root = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/clips/'\n",
    "specs_root = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/features/spectrograms/'\n",
    "noise_root = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/noise/'\n",
    "snr_clipping_root = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/features/snr_clipping/amplitude_segmented/'\n",
    "\n",
    "#csv of annotated segments (start and stop times) from the development dataset\n",
    "test_set_path = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/annotated/annotations_csv/all_annotations.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33ede5",
   "metadata": {},
   "source": [
    "# segment the audio using amplitude thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c900b",
   "metadata": {},
   "source": [
    "## set the segmenting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51c92190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T09:31:45.448614Z",
     "start_time": "2022-06-20T09:31:45.443272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making this directory:\n",
      "\t /n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/segments/bw_po_cf/amplitude_segmented/20230206_050454\n",
      "making this directory:\n",
      "\t /n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/segments/bw_po_cf/amplitude_segmented/20230206_050454/00_params\n",
      "making a new params file...\n",
      "saved the params file to:\n",
      " /n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/segments/bw_po_cf/amplitude_segmented/20230206_050454/00_params/bw_po_cf_20230206_050454\n",
      "\n",
      "iteration is: 20230206_050454\n"
     ]
    }
   ],
   "source": [
    "#choose the parameters for all species except MZ\n",
    "thresholds_path = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/noise/all_noise_floors.csv'\n",
    "seg_params = {\n",
    "    'min_freq': 20e3, # minimum frequency\n",
    "    'max_freq': 125e3, # maximum frequency\n",
    "    'nperseg': 1024, # FFT\n",
    "    'noverlap': 1024//2, # FFT\n",
    "    'spec_min_val': .8, # minimum log-spectrogram value\n",
    "    'spec_max_val': 6, # maximum log-spectrogram value\n",
    "    'fs': 250000, # audio samplerate\n",
    "    'th_1':.3, # segmenting threshold 1\n",
    "    'th_2':.3, # segmenting threshold 2\n",
    "    'th_3':.35, # segmenting threshold 3\n",
    "    'min_dur':0.015, # minimum syllable duration\n",
    "    'max_dur': 1, # maximum syllable duration\n",
    "    'min_intersyllable': .004,\n",
    "    'smoothing_timescale': 0.00025, # amplitude\n",
    "    'softmax': False, # apply softmax to the frequency bins to calculate\n",
    "                      # amplitude\n",
    "    'temperature':0.01, # softmax temperature parameter\n",
    "    'thresholds_path': None,\n",
    "    'algorithm': '<function get_onsets_offsets at 0x7f944cc355f0>', # (defined above)\n",
    "}\n",
    "\n",
    "\n",
    "#name them\n",
    "dataset = 'bw_po_cf'\n",
    "iteration = parameters.get_date_time()\n",
    "params_save_name = ('_').join([dataset,iteration])\n",
    "params_save_dir = os.path.join(segments_root,dataset,'amplitude_segmented',iteration,'00_params')+'/'\n",
    "\n",
    "\n",
    "#make directories for them\n",
    "if iteration not in os.listdir(os.path.join(segments_root,dataset, 'amplitude_segmented')):\n",
    "    path_to_make = os.path.join(segments_root,dataset,'amplitude_segmented',iteration)\n",
    "    os.mkdir(path_to_make)\n",
    "    print('making this directory:\\n\\t', path_to_make)\n",
    "    \n",
    "if '00_params' not in os.listdir(os.path.join(segments_root,dataset,'amplitude_segmented',iteration)):\n",
    "    path_to_make = os.path.join(segments_root,dataset,'amplitude_segmented',iteration,'00_params')\n",
    "    os.mkdir(path_to_make)\n",
    "    print('making this directory:\\n\\t', path_to_make)\n",
    "\n",
    "#save them\n",
    "assert os.path.exists(params_save_dir)\n",
    "assert params_save_dir.endswith('/')\n",
    "parameters.save(params = seg_params, save_dir = params_save_dir, save_name = params_save_name)\n",
    "print('\\niteration is:', iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b9d91bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making a new params file...\n",
      "saved the params file to:\n",
      " /n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/segments/development/amplitude_segmented/20230118_083823/00_params/MZ_development_20230118_083823\n"
     ]
    }
   ],
   "source": [
    "#choose the parameters for  MZ\n",
    "thresholds_path = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/noise/all_noise_floors.csv'\n",
    "seg_params = {\n",
    "    'min_freq': 20e3, # minimum frequency\n",
    "    'max_freq': 125e3, # maximum frequency\n",
    "    'nperseg': 1024, # FFT\n",
    "    'noverlap': 1024//2, # FFT\n",
    "    'spec_min_val': 2, # minimum log-spectrogram value\n",
    "    'spec_max_val': 6, # maximum log-spectrogram value\n",
    "    'fs': 250000, # audio samplerate\n",
    "    'th_1':.3, # segmenting threshold 1\n",
    "    'th_2':.3, # segmenting threshold 2\n",
    "    'th_3':.35, # segmenting threshold 3\n",
    "    'min_dur':0.015, # minimum syllable duration\n",
    "    'max_dur': 1, # maximum syllable duration\n",
    "    'min_intersyllable': .004,\n",
    "    'smoothing_timescale': 0.00025, # amplitude\n",
    "    'softmax': False, # apply softmax to the frequency bins to calculate\n",
    "                      # amplitude\n",
    "    'temperature':0.01, # softmax temperature parameter\n",
    "    'thresholds_path': None,\n",
    "    'algorithm': '<function get_onsets_offsets at 0x7f944cc355f0>', # (defined above)\n",
    "}\n",
    "\n",
    "\n",
    "#name them\n",
    "params_save_name = ('_').join(['MZ',dataset,iteration])\n",
    "params_save_dir = os.path.join(segments_root,dataset,'amplitude_segmented',iteration,'00_params')+'/'\n",
    "\n",
    "#save them\n",
    "assert os.path.exists(params_save_dir)\n",
    "assert params_save_dir.endswith('/')\n",
    "parameters.save(params = seg_params, save_dir = params_save_dir, save_name = params_save_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31b0b7",
   "metadata": {},
   "source": [
    "## segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71a2cf26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T09:31:54.501740Z",
     "start_time": "2022-06-20T09:31:54.437225Z"
    }
   },
   "outputs": [],
   "source": [
    "#get raw audio to segment\n",
    "\n",
    "# change these if you want to keep segmenting from a previous iterationn\n",
    "\n",
    "if dataset == 'development':\n",
    "    raw_dir = all_wav_raw\n",
    "elif dataset == 'bw_po_cf':\n",
    "    raw_dir = all_wav_bw_po_cf\n",
    "elif dataset == 'bw_po_f1':\n",
    "    raw_dir = all_wav_bw_po_f1\n",
    "elif dataset == 'bw_po_f2':\n",
    "    raw_dir = all_wav_bw_po_f2\n",
    "\n",
    "if dataset == 'bw_po_cf':\n",
    "    species_list = ['BW', 'PO', 'CF-BW', 'CF-PO']\n",
    "elif dataset == 'development':\n",
    "    species_list = ['NB', 'PO', 'MZ', 'BK', 'LL', 'MU', 'BW', 'GO', 'SW', 'LO', 'IS']\n",
    "\n",
    "#TO DO just remove these from the raw data\n",
    "#if the dataset is bw_po_f2, ensure that the corrupted unsegmented files aren't in raw_dir\n",
    "unsegmentable = ['ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup4_ch8_4700_f_333_298_fr0_p9_2021-04-16_15-26-07.wav',\n",
    "                 'ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup7_ch8_3800_f_338_285_fr0_p7_2021-04-14_17-27-18.wav',\n",
    "                 'ch8_BWxPO-cross-F2_27404x27407_fam-A7_ltr1_pup7_ch8_4200_m_328_275_fr1_p7_2021-01-05_13-47-10.wav']\n",
    "\n",
    "for i in unsegmentable:\n",
    "    assert i not in os.listdir(raw_dir)\n",
    "\n",
    "#specify the directory where segment csvs will be saved\n",
    "save_dir = os.path.join(segments_root,dataset,'amplitude_segmented',iteration)\n",
    "\n",
    "#load the params and make sure everything looks ok\n",
    "print('\\ndata set is:\\n\\t',dataset, '\\n')\n",
    "\n",
    "# load the parameters\n",
    "params_save_dir = os.path.join(segments_root,dataset,'amplitude_segmented',iteration,'00_params')+'/'\n",
    "params_save_name = ('_').join([dataset,iteration])\n",
    "seg_params = parameters.load(save_dir = params_save_dir, save_name = params_save_name)\n",
    "\n",
    "if dataset == 'development':\n",
    "    MZ_seg_params = parameters.load(save_dir = params_save_dir, save_name = ('_').join(['MZ',dataset,iteration]))\n",
    "\n",
    "print('\\nthey are:\\n')\n",
    "for key in seg_params.keys():\n",
    "    print('\\t',key,':',seg_params[key])\n",
    "\n",
    "if dataset == 'development':\n",
    "    print('\\nMZ specific params are:\\n')\n",
    "    for key in seg_params.keys():\n",
    "        print('\\t',key,':',MZ_seg_params[key])\n",
    "\n",
    "print('\\nstart and stop times will be identified in raw wav files here:\\n\\t', raw_dir)\n",
    "print('\\nand saved here:\\n\\t', save_dir)\n",
    "    \n",
    "val = input('everything look ok for segmenting? y/n')\n",
    "assert val in ['y','n']\n",
    "if val == 'n':\n",
    "    print('ok - doing nothing')\n",
    "elif val == 'y':\n",
    "    \n",
    "    #iterate through each species you want and segment\n",
    "    for species in species_list:\n",
    "        \n",
    "        #get the MZ specific parameters if you're segmenting MZ\n",
    "        if species=='MZ':\n",
    "            seg_params = parameters.load(save_dir = params_save_dir, save_name = ('_').join(['MZ',dataset,iteration]))\n",
    "            \n",
    "        segmentation.get_amplitude_segments(audio_dir = raw_dir, \n",
    "                                            save_dir = save_dir, \n",
    "                                            seg_params = seg_params, \n",
    "                                            species = species, \n",
    "                                            thresholds_path = seg_params['thresholds_path'],\n",
    "                                            intersyll_threshold = seg_params['min_intersyllable'], \n",
    "                                            duration_threshold = seg_params['min_dur'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827c58",
   "metadata": {},
   "source": [
    "## aggregate the segments files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5bf483ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the dataset and segmenting iteration if you want (otherwise will existing values for dataset and iteration \n",
    "#- these are the only things you have to change in this cell to process a new dataset \n",
    "# dataset = 'bw_po_f2'\n",
    "# iteration = '20220921_040238'\n",
    "\n",
    "#path to the dir containing one csv with segment start and stop times per raw audio file\n",
    "segments_path = os.path.join(segments_root,dataset,'amplitude_segmented',iteration)\n",
    "\n",
    "\n",
    "\n",
    "#make sure you segmented every wav file\n",
    "if dataset == 'development':\n",
    "    all_wav_raw = all_wav_raw\n",
    "elif dataset == 'bw_po_cf':\n",
    "    all_wav_raw = all_wav_bw_po_cf\n",
    "elif dataset == 'bw_po_f1':\n",
    "    all_wav_raw = all_wav_bw_po_f1\n",
    "elif dataset == 'bw_po_f2':\n",
    "    all_wav_raw = all_wav_bw_po_f2\n",
    "\n",
    "\n",
    "raw_wavs = [i for i in os.listdir(all_wav_raw) if not i.startswith('.')]\n",
    "segmented_wavs = [i.split('.')[0]+'.wav' for i in os.listdir(segments_path) if not i.startswith('.') and 'all' not in i]\n",
    "assert sorted(raw_wavs) == sorted(segmented_wavs), \"You haven't segmented all of the raw wav files...\"\n",
    "\n",
    "#make a list of the segments files for each pup\n",
    "pup_segments = [os.path.join(segments_path, i) for i in os.listdir(segments_path) if i.endswith('.csv') and 'all' not in i and not i.startswith('.')]\n",
    "\n",
    "#combine them\n",
    "to_combine = []\n",
    "for temp in pup_segments:\n",
    "    temp_df = pd.read_csv(temp)   \n",
    "    to_combine.append(temp_df)\n",
    "    \n",
    "all_combined = pd.concat(to_combine)\n",
    "\n",
    "#add species column info and fix up the source_file columns\n",
    "all_combined['species'] = [i.split('/')[-1].split('_')[0] for i in all_combined['source_file']]\n",
    "all_combined['source_file'] = [os.path.split(i)[-1] for i in all_combined['source_file']]\n",
    "\n",
    "#check for na and duplications, make sure source file is formatted correctly, then save\n",
    "\n",
    "assert all_combined.isna().sum().sum() == 0\n",
    "assert all_combined.duplicated().sum() == 0\n",
    "assert set([i.split('_')[0] for i in all_combined['source_file']]) == set(all_combined['species'])\n",
    "all_combined.to_csv(os.path.join(segments_path, 'all_combined.csv'), index=False)\n",
    "print('saved a combined file to:\\n\\t', os.path.join(segments_path, 'all_combined.csv'))\n",
    "\n",
    "#preview to make sure column names look ok\n",
    "all_combined.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fafb07",
   "metadata": {},
   "source": [
    "# generate wav clips from amplitude segmented segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eded6b7",
   "metadata": {},
   "source": [
    "## write wav files for vocalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "70e047c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the dataset and iteration\n",
    "\n",
    "#load the combined segments csv\n",
    "segments_path = os.path.join(segments_root,dataset,'amplitude_segmented',iteration)\n",
    "source_data_path = os.path.join(segments_path, 'all_combined.csv')\n",
    "source_data = pd.read_csv(source_data_path)\n",
    "\n",
    "#make it's what you expect and that you cleaned up any na and duplications\n",
    "assert source_data.isna().sum().sum() == 0\n",
    "assert source_data.duplicated().sum() == 0\n",
    "assert set(source_data.columns) == set(['start_seconds', 'stop_seconds', 'source_file', 'duration', 'species'])\n",
    "\n",
    "if dataset == 'bw_po_cf':\n",
    "    assert set(source_data['species'].unique()) == set(['BW', 'PO', 'CF-BW', 'CF-PO'])\n",
    "elif dataset == 'bw_po_f1':\n",
    "    assert set(source_data['species'].unique()) == set(['cross-BW', 'cross-PO', 'BW-PO-cross-F1'])\n",
    "elif dataset == 'bw_po_f2':\n",
    "    assert set(source_data['species'].unique()) == set(['ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7', 'ch8'])\n",
    "    #drop the unsegmentable bw_po_f2\n",
    "    unsegmentable = ['ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup4_ch8_4700_f_333_298_fr0_p9_2021-04-16_15-26-07.wav',\n",
    "                 'ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup7_ch8_3800_f_338_285_fr0_p7_2021-04-14_17-27-18.wav',\n",
    "                 'ch8_BWxPO-cross-F2_27404x27407_fam-A7_ltr1_pup7_ch8_4200_m_328_275_fr1_p7_2021-01-05_13-47-10.wav']\n",
    "    source_data = source_data.loc[~source_data['source_file'].isin(unsegmentable)]\n",
    "    \n",
    "elif dataset == 'development':\n",
    "    assert sorted(species_list) == sorted(['BW', 'BK', 'NB', 'SW', 'PO', 'LO', 'GO', 'LL', 'MU', 'MZ'])\n",
    "    \n",
    "#get the path to the raw unsegmented wavs\n",
    "if dataset == 'bw_po_cf':\n",
    "    wavs_dir = all_wav_bw_po_cf\n",
    "elif dataset == 'bw_po_f1':\n",
    "    wavs_dir = all_wav_bw_po_f1\n",
    "elif dataset == 'bw_po_f2':\n",
    "    wavs_dir = all_wav_bw_po_f2\n",
    "elif dataset == 'development':\n",
    "    wavs_dir = all_wav_raw\n",
    "            \n",
    "bar = '######################################################################################################'\n",
    "#set the directory for saving and make it TODO - get the data from datetime\n",
    "save_root = os.path.join(clips_root,'amplitude_segmented',dataset, iteration)\n",
    "if iteration not in os.listdir(os.path.join(clips_root,'amplitude_segmented',dataset)):\n",
    "    os.mkdir(save_root)\n",
    "    print('made a directory to save vocalization clips:', save_root)\n",
    "assert os.path.exists(save_root)\n",
    "\n",
    "print(bar)\n",
    "print('segmenting wavs from this directory:\\n\\n',wavs_dir,'\\n')\n",
    "print(bar)\n",
    "print('using start and stop times from this file:\\n\\n',source_data_path,'\\n')\n",
    "print(bar)\n",
    "print('saving them to individual species directories here:\\n\\n',save_root,'\\n')\n",
    "print(bar)\n",
    "print('those species are:\\n\\n',sorted(source_data['species'].unique()),'\\n')\n",
    "print(bar)\n",
    "print(len(source_data), 'vocalization clips will be written to wav files')\n",
    "\n",
    "val = input(\"continue? y/n\")\n",
    "assert val in ['y', 'n']\n",
    "if val == 'n':\n",
    "    print('ok - doing nothing.')\n",
    "elif val == 'y':\n",
    "#iterate through the species   \n",
    "    species_list = list(source_data['species'].unique())                    \n",
    "    for species in species_list:\n",
    "        print(species)\n",
    "        \n",
    "        save_location = os.path.join(save_root,species)\n",
    "        start_column = 'start_seconds'\n",
    "        end_column = 'stop_seconds'\n",
    "\n",
    "        if species not in os.listdir(save_root):\n",
    "            print('making a directory to store', species, 'vocalization clips...')\n",
    "            os.mkdir(save_location)\n",
    "\n",
    "        segmentation.get_wav_clips(wavs_dir = wavs_dir, \n",
    "                                   save_location = save_location, \n",
    "                                   source_data = source_data, \n",
    "                                   start_column = start_column, \n",
    "                                   end_column = end_column,\n",
    "                                   label_column = None,\n",
    "                                   species = species,\n",
    "                                   margin = 0, \n",
    "                                   units = 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe472c9",
   "metadata": {},
   "source": [
    "## write wav files for inter-vocalization intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bfe21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment background using - useful for finding wav clips that don't have any vocalizations in them\n",
    "# dataset = 'bw_po_f2'\n",
    "# iteration = '20220921_040238'\n",
    "\n",
    "#choose the species and directories where things will be saved\n",
    "species =['MZ']\n",
    "\n",
    "#name the columns that will record start and stop time of background in seconds\n",
    "start_column = 'start_seconds'\n",
    "stop_column = 'stop_seconds'\n",
    "\n",
    "#set directories automatically \n",
    "raw_wavs_dir = os.path.join(all_wavs_raw, dataset, iteration)\n",
    "save_dir = os.path.join(save_dir, '01_background_clips')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.path.mkdir(save_dir)\n",
    "    print('made a directory at', save_dir)\n",
    "\n",
    "#path to the csv made in the previous cell\n",
    "all_segments_df = os.path.join(segments_path, 'all_combined.csv')\n",
    "\n",
    "\n",
    "for s in species:\n",
    "    save_location = save_dir+s+'/'\n",
    "\n",
    "    #make a directory for the species\n",
    "    if s not in os.listdir(save_dir):\n",
    "        print('making a directory to store', s, 'background clips...')\n",
    "        save_location = save_dir+s+'/'\n",
    "        os.mkdir(save_location)\n",
    "        \n",
    "    segmentation.get_background_clips(raw_wavs_dir=raw_wavs_dir , \n",
    "                                      save_location=save_location, \n",
    "                                      all_segments_df=all_segments_df,\n",
    "                                      start_column=start_column, \n",
    "                                      stop_column=stop_column, \n",
    "                                      label_column = None, \n",
    "                                      species = s, \n",
    "                                      units = 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc4670",
   "metadata": {},
   "source": [
    "## choose noise clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a2b4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best to run this cell one species at a time and save clips to species specific directories\n",
    "species = 'BK'\n",
    "\n",
    "#path to directory containing raw audio\n",
    "audio_dir = all_wav_raw\n",
    "\n",
    "#path to directory containing segments generated in section 2.2 above\n",
    "dataset = 'development'\n",
    "iteration='20230118_083823' \n",
    "seg_df = os.path.join(segments_root,dataset,'amplitude_segmented',iteration, 'all_combined.csv')\n",
    "\n",
    "#path to save wav clips\n",
    "save_dir = os.path.join(noise_root, 'test_20230120', species)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    print('made the directory', save_dir)\n",
    "\n",
    "pups = sorted([i.split('.')[0] for i in os.listdir(all_wav_raw) if species in i])\n",
    "\n",
    "for pup in pups:\n",
    "    annotation.get_noise_clip(pup=pup, \n",
    "                              audio_dir=audio_dir, \n",
    "                              seg_csv=seg_df, \n",
    "                              save_dir=save_dir, \n",
    "                              margin=0, \n",
    "                              min_dur=2, \n",
    "                              max_dur=3, \n",
    "                              units = 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03aacac",
   "metadata": {},
   "source": [
    "## calculate noise floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "24a80e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "#use the background clips in cell 3.3 above to calculate \"noise floors\", ie the spectrogram value\n",
    "#below which you will consider a pixel \"background\"\n",
    "\n",
    "save_dir = os.path.join(noise_root, 'test_20230120')\n",
    "species_list = ['BW', 'BK', 'NB', 'SW', 'PO', 'LO', 'GO', 'LL', 'MU', 'MZ', 'IS']\n",
    "\n",
    "\n",
    "noise_spec_params = {\n",
    "    'min_freq': 5000, # minimum frequency\n",
    "    'max_freq': 125000, # maximum frequency\n",
    "    'nperseg': 512, # FFT\n",
    "    'noverlap': 512 // 4, # FFT\n",
    "    'fs': 250000, # audio samplerate\n",
    "\n",
    "}\n",
    "\n",
    "parameters.save_parameters(params = noise_spec_params, \n",
    "                           save_dir = save_root, \n",
    "                           save_name = 'noise_spec_params')\n",
    "\n",
    "noise_floors_df = []\n",
    "for species in species_list:\n",
    "    df =  annotation.get_noise_floor(noise_dir = os.path.join(noise_root, species), \n",
    "                                     thresh = 2, \n",
    "                                     species = species, \n",
    "                                     save_dir = save_dir,\n",
    "                                     spec_params = noise_spec_params, \n",
    "                                     verbose=False, \n",
    "                                     save = False)\n",
    "    \n",
    "    noise_floors_df.append(df)\n",
    "\n",
    "new = pd.concat(noise_floors_df)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62513de8",
   "metadata": {},
   "source": [
    "# get SNR and clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3dd3c3",
   "metadata": {},
   "source": [
    "## set spectrogramming parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7d89e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T13:10:41.043897Z",
     "start_time": "2022-06-15T13:10:41.038199Z"
    }
   },
   "outputs": [],
   "source": [
    "#choose params that match the ones you will use for getting features\n",
    "noise_spec_params = {\n",
    "    'min_freq': 5000, # minimum frequency\n",
    "    'max_freq': 12500, # maximum frequency\n",
    "    'nperseg': 1024, # FFT\n",
    "    'noverlap': 1024 // 4, # FFT\n",
    "    'fs': 250000, # audio samplerate\n",
    "}\n",
    "\n",
    "spec_params = {\n",
    "    'min_freq': 5000, # minimum frequency\n",
    "    'max_freq': 124999, # maximum frequency\n",
    "    'nperseg': 256, # FFT\n",
    "    'noverlap': 256 // 4, # FFT\n",
    "    'spec_min_val': 0.7, # minimum log-spectrogram value\n",
    "    'fs': 250000, # audio samplerate\n",
    "    'downsample_by':2, #2 means take every other pixel from the original spectrogram\n",
    "    'log_resize_scaling_factor':None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107d191",
   "metadata": {},
   "source": [
    "## get noise floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d703ab4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T11:46:13.552205Z",
     "start_time": "2022-06-15T11:46:12.965033Z"
    }
   },
   "outputs": [],
   "source": [
    "noise_floors_path = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/noise/all_noise_floors.csv'\n",
    "nfdf = pd.read_csv(noise_floors_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9c1b9",
   "metadata": {},
   "source": [
    "## get clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "552740a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T09:01:40.807108Z",
     "start_time": "2022-07-05T09:01:40.804370Z"
    }
   },
   "outputs": [],
   "source": [
    "clipping_threshold = 0.95\n",
    "dataset = 'bw_po_cf'\n",
    "iteration = '20230206_050454'\n",
    "#iteration = '20230206_99thresh'\n",
    "save = True\n",
    "\n",
    "if save:\n",
    "    if not os.path.exists(os.path.join(snr_clipping_root,dataset,iteration)):\n",
    "        os.mkdir(os.path.join(snr_clipping_root,dataset,iteration))\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "if dataset == 'bw_po_cf':\n",
    "    to_process_dir = os.path.join(all_clips_bw_po_cf, iteration)\n",
    "    species_list = os.listdir(to_process_dir)\n",
    "    assert set(species_list) == set(['BW', 'PO', 'CF-BW', 'CF-PO'])\n",
    "    \n",
    "elif dataset == 'bw_po_f1':\n",
    "    to_process_dir = all_clips_bw_po_f1\n",
    "    species_list = os.listdir(to_process_dir)\n",
    "    assert set(species_list) == set(['cross-BW', 'cross-PO', 'BW-PO-cross-F1'])\n",
    "    \n",
    "elif dataset == 'bw_po_f2':\n",
    "    to_process_dir = all_clips_bw_po_f2\n",
    "    species_list = os.listdir(to_process_dir)\n",
    "    assert set(species_list) == set(['ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7', 'ch8'])\n",
    "    \n",
    "    #drop the unsegmentable bw_po_f2\n",
    "    unsegmentable = ['ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup4_ch8_4700_f_333_298_fr0_p9_2021-04-16_15-26-07.wav',\n",
    "                 'ch8_BWxPO-cross-F2_26878x27490_fam-D3_ltr6_pup7_ch8_3800_f_338_285_fr0_p7_2021-04-14_17-27-18.wav',\n",
    "                 'ch8_BWxPO-cross-F2_27404x27407_fam-A7_ltr1_pup7_ch8_4200_m_328_275_fr1_p7_2021-01-05_13-47-10.wav']\n",
    "    source_data = source_data.loc[~source_data['source_file'].isin(unsegmentable)]\n",
    "    \n",
    "elif dataset == 'development':\n",
    "    print('dataset is:', dataset)\n",
    "    to_process_dir = all_clips_development\n",
    "    species_list = os.listdir(to_process_dir)\n",
    "    assert sorted(species_list) == sorted(['BW', 'BK', 'NB', 'SW', 'PO', 'LO', 'GO', 'LL', 'MU', 'MZ', 'IS'])\n",
    "\n",
    "#get clipping percents and corresponding to each wav file\n",
    "\n",
    "clipping_dfs = []\n",
    "for species in species_list:\n",
    "    print('calculating clipping for each vocalization clip in:\\n\\t', os.path.join(to_process_dir, species))\n",
    "    clipping_df = features.get_clipping_batch(wav_dir = os.path.join(to_process_dir, species),\n",
    "                                              threshold = clipping_threshold, \n",
    "                                              species = species)\n",
    "    if save:\n",
    "        save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
    "        save_name = ('_').join([species,'clipping.csv'])\n",
    "        \n",
    "        if save_name not in os.listdir(save_dir):\n",
    "            clipping_df.to_csv(os.path.join(save_dir,save_name), index=False)\n",
    "            print('\\tsaved clipping csv to:', os.path.join(save_dir,save_name))\n",
    "        else:\n",
    "            print('\\tclipping csv already exists...')\n",
    "\n",
    "print('done.')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07288280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved a file: /n/hoekstra_lab_tier1/Users/njourjine/manuscript/features/snr_clipping/amplitude_segmented/bw_po_cf/20230206_050454/all_bw_po_cf_clipping.csv\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "## aggregate clipping cvs\n",
    "\n",
    "save = True\n",
    "\n",
    "dataset = 'bw_po_cf'\n",
    "iteration = iteration\n",
    "\n",
    "save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
    "save_name = ('_').join(['all', dataset, 'clipping.csv'])\n",
    "to_aggregate = [i for i in glob.glob(os.path.join(save_dir, '*clipping.csv')) if os.path.split(i)[-1] != save_name]\n",
    "\n",
    "all_clipping = []\n",
    "for file in to_aggregate:\n",
    "    df = pd.read_csv(file)\n",
    "    all_clipping.append(df)\n",
    "\n",
    "all_clipping_df = pd.concat(all_clipping)\n",
    "\n",
    "if save:\n",
    "    save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
    "    if not os.path.exists(os.path.join(save_dir,save_name)):\n",
    "        all_clipping_df.to_csv(os.path.join(save_dir,save_name), index=False)\n",
    "        print('saved a file:', os.path.join(save_dir,save_name))\n",
    "        \n",
    "print('done.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac09cf0",
   "metadata": {},
   "source": [
    "## get signal to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "342fef32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T13:19:59.737858Z",
     "start_time": "2022-06-15T13:16:01.796438Z"
    }
   },
   "outputs": [],
   "source": [
    "# save = True\n",
    "# # dataset = 'development'\n",
    "# # iteration = 'final_20220817'\n",
    "\n",
    "# #choose the algorithm for calculating snr\n",
    "# # algorithm = 2\n",
    "\n",
    "# ################################################################################################################\n",
    "\n",
    "# if dataset == 'bw_po_cf':\n",
    "#     to_process_dir = all_clips_bw_po_cf\n",
    "#     species_list = os.listdir(to_process_dir)\n",
    "#     assert set(species_list) == set(['BW', 'PO', 'CF-BW', 'CF-PO'])\n",
    "    \n",
    "# elif dataset == 'bw_po_f1':\n",
    "#     to_process_dir = all_clips_bw_po_f1\n",
    "#     species_list = os.listdir(to_process_dir)\n",
    "#     assert set(species_list) == set(['cross-BW', 'cross-PO', 'BW-PO-cross-F1'])\n",
    "    \n",
    "# elif dataset == 'bw_po_f2':\n",
    "#     to_process_dir = all_clips_bw_po_f2\n",
    "#     species_list = os.listdir(to_process_dir)\n",
    "#     assert set(species_list) == set(['ch1', 'ch2', 'ch3', 'ch4', 'ch5', 'ch6', 'ch7', 'ch8'])\n",
    "\n",
    "# #get signal to noise and corresponding to each wav file\n",
    "# for species in species_list:\n",
    "#     print('calculating snr for each vocalization clip in:\\n\\t', os.path.join(to_process_dir, species))\n",
    "#     snr_df = features.get_snr_batch(clips_dir = os.path.join(to_process_dir, species),\n",
    "#                                     noise_dir = os.path.join(noise_root, species),\n",
    "#                                     algorithm=algorithm,\n",
    "#                                     species = species)\n",
    "#     if save:\n",
    "#         save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
    "#         save_name = ('_').join([species,'snr.csv'])\n",
    "#         snr_df.to_csv(os.path.join(save_dir,save_name), index=False)\n",
    "#         print('saved clipping csv to:', os.path.join(save_dir,save_name))\n",
    "\n",
    "# print('done.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # snr_df = get_snr_batch(clip_dir = wav_dir, \n",
    "# #                        noise_dir = noise_dir, \n",
    "# #                        algorithm=2,\n",
    "# #                        species = 'BW')\n",
    "\n",
    "# # #save because this takes a long time\n",
    "# # snr_df.to_csv('/Users/nick_jourjine/Desktop/snr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "593c2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate snr csvs\n",
    "\n",
    "dataset = 'development'\n",
    "iteration = 'final_20220817'\n",
    "\n",
    "save = True\n",
    "\n",
    "save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
    "save_name = 'all_development_snr.csv'\n",
    "to_aggregate = [i for i in glob.glob(os.path.join(save_dir, '*snr.csv')) if os.path.split(i)[-1] != save_name]\n",
    "\n",
    "all_development_snr = []\n",
    "for file in to_aggregate:\n",
    "    df = pd.read_csv(file)\n",
    "    all_development_snr.append(df)\n",
    "\n",
    "all_development_snr_df = pd.concat(all_development_snr)\n",
    "\n",
    "if save:\n",
    "    save_dir = os.path.join(snr_clipping_root,dataset,iteration)\n",
    "    save_name = 'all_development_snr.csv'\n",
    "    if not os.path.exists(os.path.join(save_dir,save_name)):\n",
    "        all_development_snr_df.to_csv(os.path.join(save_dir,save_name), index=False)\n",
    "        print('saved a file:', os.path.join(save_dir,save_name))\n",
    "        \n",
    "print('done.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f72cfa",
   "metadata": {},
   "source": [
    "# UMAP embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a9c2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T08:59:02.958891Z",
     "start_time": "2023-01-06T08:59:02.956283Z"
    }
   },
   "source": [
    "## set species and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edae9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO clean up comments\n",
    "\n",
    "#set the species to process\n",
    "species_list = ['PO','BW', 'BK', 'NB', 'SW', 'LO', 'GO', 'LL', 'MU', 'MZ']\n",
    "\n",
    "#the dataset for umap\n",
    "dataset = 'development'\n",
    "segment_iteration = '20230118_083823' #this is the segmenting iteration for the segments in the preprint\n",
    "\n",
    "#unique iteration ID for each time you do an embedding for a dataset\n",
    "#umap_iteration = parameters.get_date_time()\n",
    "umap_iteration = '20230120_105045'\n",
    "\n",
    "#all predicted start and stop times for this dataset\n",
    "aggregated_segments_path = os.path.join(segments_root,dataset,'amplitude_segmented',segment_iteration,'all_combined.csv')\n",
    "seg_df = pd.read_csv(aggregated_segments_path)\n",
    "\n",
    "#path to wav files for each segmented vocalization\n",
    "all_wav_dir = os.path.join(clips_root,'amplitude_segmented',dataset,segment_iteration)\n",
    "assert os.path.exists(all_wav_dir)\n",
    "\n",
    "#path to directory where spectrograms and umap embedding coordinates will be save\n",
    "all_spec_dir = os.path.join(specs_root,'amplitude_segmented',dataset, segment_iteration)\n",
    "if segment_iteration not in os.listdir(os.path.join(specs_root,'amplitude_segmented',dataset)):\n",
    "    os.mkdir(all_spec_dir)\n",
    "    print('made a directory to store spectrograms for umap embeddings :\\t\\n', all_spec_dir, '\\n')\n",
    "assert os.path.exists(all_spec_dir)\n",
    "\n",
    "#path to the noise floors csvs generated by annotation.get_noise_clip() and annotation.get_noise_floor()\n",
    "noise_floors_path = '/n/hoekstra_lab_tier1/Users/njourjine/manuscript/audio/noise/all_noise_floors.csv'\n",
    "assert os.path.exists(noise_floors_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcbaae",
   "metadata": {},
   "source": [
    "## choose and save spectrogram parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5bca9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the spec params\n",
    "\n",
    "umap_iteration = '20230120_105045'\n",
    "\n",
    "#make necessary directories for spectrograms\n",
    "specs_dir = os.path.join(all_spec_dir,umap_iteration)+'/'\n",
    "if umap_iteration not in os.listdir(all_spec_dir):\n",
    "    os.mkdir(specs_dir)\n",
    "    print('made a root directory to store umap embeddings from this version_name:\\t\\n', specs_dir, '\\n')\n",
    "\n",
    "if '00_params' not in os.listdir(specs_dir):\n",
    "    os.mkdir(os.path.join(specs_dir,'00_params'))\n",
    "    print('made a params directory to store umap embeddings from this version_name:\\t\\n', specs_dir+'00_params\\n')\n",
    "\n",
    "#write the params dictionaries for each species\n",
    "for species in species_list:\n",
    "    species_param_name = ('_').join([species,'spec_params',umap_iteration])\n",
    "    species_wav_clips_dir = os.path.join(clips_root, 'amplitude_segmented', dataset, segment_iteration, 'vocalization_clips', species)\n",
    "    max_dur = float(np.max(seg_df['duration'].loc[seg_df['species'] == species]))\n",
    "    print('longest predicted voc from', species, 'is', max_dur, 'seconds')\n",
    "\n",
    "    spec_params = {\n",
    "        'species': species,\n",
    "        'min_freq': 5000, # minimum frequency\n",
    "        'max_freq': 125000, # maximum frequency\n",
    "        'nperseg': 512, # FFT\n",
    "        'noverlap': 512 // 4, # FFT\n",
    "        'spec_min_val': .5, # minimum log-spectrogram value - update from noise floors dataframe if noise_floors_path provided\n",
    "        'fs': 250000, # audio samplerate\n",
    "        'fill_value': .5,\n",
    "        'max_duration':max_dur,\n",
    "        'num_time_bins':128,\n",
    "        'num_freq_bins':128,\n",
    "        'spec_max_val':10,\n",
    "        'wav_clips_source':species_wav_clips_dir,\n",
    "        'noise_floors_path': noise_floors_path\n",
    "    }\n",
    "\n",
    "    #save spec params if they don't exist\n",
    "    parameters.save_parameters(spec_params, os.path.join(specs_dir,'00_params'), species_param_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfadac1",
   "metadata": {},
   "source": [
    "## find UMAP embeddings for each species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab4c85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the directory for saving and make it TODO - get the data from datetime\n",
    "dataset = 'development'\n",
    "species_list = ['PO','BW', 'BK', 'NB', 'SW', 'LO', 'GO', 'LL', 'MU', 'MZ']\n",
    "segment_iteration = '20230118_083823'\n",
    "umap_iteration = '20230120_105045'\n",
    "\n",
    "for species in species_list:\n",
    "    print('##########################################################################')\n",
    "    species_wav_clips_dir = os.path.join(clips_root, 'amplitude_segmented', dataset, segment_iteration, 'vocalization_clips', species)\n",
    "    species_param_name = ('_').join([species,'spec_params',umap_iteration])\n",
    "    print(species)\n",
    "    print('##########################################################################')\n",
    "    print('getting umap embedding from wav clips here.......\\n\\n',species_wav_clips_dir ,'\\n')\n",
    "    print('using these parameters..............\\n\\n', os.path.join(specs_dir+'00_params/', species_param_name), '\\n')\n",
    "    print('and saving umap coordinates here.......\\n\\n',specs_dir,'\\n')\n",
    "    print(len(seg_df.loc[seg_df['species'] == species]), 'vocalization clips will be processed')\n",
    "    \n",
    "val = input('continue?' 'y/n')\n",
    "\n",
    "assert val in ['y', 'n']\n",
    "\n",
    "if val == 'n':\n",
    "    print('ok - doing nothing.')\n",
    "\n",
    "elif val == 'y':\n",
    "    \n",
    "    for species in species_list:\n",
    "        params_dir = os.path.join(specs_dir+'00_params/')\n",
    "        params_name = ('_').join([species,'spec_params',umap_iteration])\n",
    "        \n",
    "        #load the spec params\n",
    "        print('loading parameters...')\n",
    "        spec_params = parameters.load_parameters(params_dir, params_name)\n",
    "        print('done.')\n",
    "        \n",
    "        #get the clips for the embedding (excluding noise)\n",
    "        print('getting paths to wav clips...')\n",
    "        clips_to_process = [i for i in glob.glob(os.path.join(spec_params['wav_clips_source'],'*.wav'))]\n",
    "        print('done.')\n",
    "\n",
    "        #make the umap\n",
    "        print('getting umap embeddings...')\n",
    "        spectrogramming.wavs_to_umap(clips_dir=None, \n",
    "                                     noise_floors_path = spec_params['noise_floors_path'],\n",
    "                                     species = None, \n",
    "                                     noise_floor = None, \n",
    "                                     spec_params = spec_params, \n",
    "                                     num_to_process = 'all', \n",
    "                                     filtered_clips = clips_to_process, \n",
    "                                     version=umap_iteration, \n",
    "                                     save_root = specs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manuscript",
   "language": "python",
   "name": "manuscript"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.99px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
